{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root Finding: Univariate Functions\n",
    "\n",
    "## Numerical Methods\n",
    "\n",
    "Students fear numerical methods because we've been training them their whole lives to solve toy problems with paper and pencil, and numerical methods have an entirely different feel.  It's unfortunate because proficiency with numerical methods opens the door to many more problems than you can find analytical solutions for, which are the norm in real engineering design.\n",
    "\n",
    "In addition, numerical solutions are generally far easier than analytical solutions...once you get the hang of it.  They are all really based around writing some sort of function that encodes the equations you want to solve and then passing that function along with a minimum set of arguments to a Python subroutine; these are usually found in `Scipy`; here' we're working on root finding for univariate functions, so we'll add the `optimize` package from `Scipy` and alias it as `opt`.  Generally speaking, `scipy.optimize` is where we'll find root finding and optimization algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Root Finding\n",
    "\n",
    "Let's start with the most straightforward case first - using numerical methods to find the root of a function. All we mean by root finding is that we are finding the value of the function argument(s) where the function is equal to zero. \n",
    "\n",
    "One key thing about learning new tools, especially numerical methods is this:\n",
    "\n",
    "**Start by solving a problem you know the answer to**.  You can get root finding algorithms and numerical methods to converge for lots of scenarios, but there is no guarantee they are giving you the correct answer.  Start on a system you can confirm, then move onto those that you can't once you've built base proficiencies.\n",
    "\n",
    "## Root Finding for Univariate Functions\n",
    "\n",
    "We will start with the case of root finding with a ***univariate function***, which basically means ***a function that only has one independent variable***. For example, \n",
    "\n",
    "$$y = f(x) = 5x^2 + 8x - 23$$ \n",
    "\n",
    "We would like to find the **roots** for that function. By that, we mean the values of x where y = 0. So, when we discuss \"root finding\" for this equation, we are simply solving the equation below for x:\n",
    "\n",
    "$$0 = 5x^2 + 8x - 23$$\n",
    "\n",
    "## The Utility of Graphing your Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y(x):\n",
    "    return 5*x**2 + 8*x - 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy arrays are probably what you want...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xplot_ndarray = np.linspace(-4, 3, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy arrays support broadcasting, so you can pass them to a function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize = (5, 5))\n",
    "plt.plot(xplot_ndarray, y(xplot_ndarray), color = 'blue')\n",
    "plt.hlines(0, -4, 3, color = 'black', linewidth = 1, linestyle = 'dashed') #Adding a y = 0\n",
    "plt.xlim(min(xplot_ndarray), max(xplot_ndarray))\n",
    "plt.ylim(-30, 50)\n",
    "plt.xlabel('X', fontsize = 12)\n",
    "plt.ylabel('Y', fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall: there is an analytical solution to this equation\n",
    "\n",
    "We know from Assignment 5 (or just recalling our math background) that we can solve this problem exactly using the quadratic equation:\n",
    "\n",
    "$$x = \\frac{-8 \\pm \\sqrt{8^2 - 4\\cdot5\\cdot-23}}{2\\cdot5}$$\n",
    "\n",
    "Solving this, we find:\n",
    "\n",
    "$$x = 1.489 \\ \\ \\textrm{or} \\ \\ x = -3.089$$\n",
    "\n",
    "This is absolutely consistent with our graphical analysis, as it should be! For me, this is a hugely important step when learning a new method:  we are establishing the correct answer using a method we are comfortable with *before* we start writing code to implement a method that is unfamiliar too us.\n",
    "\n",
    "### Newton-Raphson Method\n",
    "\n",
    "A common entry point to numerical root finding is the Newton-Raphson Method. As with most numerical analysis, this is an iterative method, but it uses information about the function value and the derivative value to make more informed iterations. The general \"formula\" for the Newton-Raphson iteration is:\n",
    "\n",
    "$$x_{i+1} = x_i - \\frac{f(x_i)}{f^\\prime(x_i)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0.0\n",
    "y = -23.0\n",
    "while abs(y) > 1e-8:\n",
    "    print(round(x,10),round(y,10))\n",
    "    y  = 5*x**2 + 8*x - 23\n",
    "    dy = 10*x + 8\n",
    "    x  = x - y/dy\n",
    "print(round(x,10),round(y,10))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the progress of the iterations\n",
    "\n",
    "Finally, for a cool visualization of how iterative root finding algorithms proceed, run this code: It will give you a graphical output of the initial guess and the updated root location after each iteration. We start it out with a rather poor initial guess (x = 10), but eventually, you'll see that it settles in and stops at the value of the true root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y(x):\n",
    "    return 5*x**2 + 8*x - 23\n",
    "def dy(x):\n",
    "    return 10*x + 8\n",
    "\n",
    "xplot = np.linspace(-4,10,10000)\n",
    "yplot = y(xplot)\n",
    "xrange = [-4, 10]\n",
    "yrange = [0, 0]\n",
    "\n",
    "x = 10\n",
    "xlist = []\n",
    "ylist = []\n",
    "while abs(y(x)) > 1e-8:\n",
    "    xlist.append(x)\n",
    "    ylist.append(y(x))\n",
    "    plt.plot(xplot,yplot, color = 'black',linewidth = 1)\n",
    "    plt.plot(xrange,yrange, linestyle = 'dashed', linewidth = 1)\n",
    "    plt.scatter(xlist, ylist, color = 'red', marker = 'o')\n",
    "    plt.show()\n",
    "    x = x - y(x)/dy(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probably we should leave numerical method scripts to the professionals...\n",
    "\n",
    "https://en.wikipedia.org/wiki/Root-finding_algorithms\n",
    "\n",
    "\n",
    "## Scipy\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/optimize.html\n",
    "\n",
    "\n",
    "### Import `Scipy.optimize()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods for root finding in univariate, scalar functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.newton(y, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.newton(y, 0, fprime = dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.newton(y,0, fprime = dy, full_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.brentq(y, -2, 2, full_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `opt.root_scalar()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.root_scalar(y, x0 = 0, fprime = dy, method = 'newton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.root_scalar(y, bracket = [-2, 2], method = 'brentq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.root_scalar(y, bracket = [-2, 2], method = 'toms748')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical root finding is difficult...\n",
    "\n",
    "Now we will add some trouble to the system. The above example is really well-behaved. It is a robust 2nd order polynomial, and pretty much anything we use - graphical, quadratic, or any available numerical methods will solve it easily. Further, you can guess almost anything for your initial value of x, or provide reasonable brackets for the solver, and the algorithm will find the correct root.  This isn't always the case.  Some equations are more difficult to handle than others, and you may have to pay close attention to your initial guess or even your choice of solver.  This example is a bit contrived, but it will illustrate the point:\n",
    "\n",
    "Consider the function:\n",
    "\n",
    "$$g(t) = -0.74 + 0.765t + 1.1t^2 - 3.55t^3$$\n",
    "\n",
    "When approaching a new problem that I will try to solve numerically, it is always helpful to graph it. Go ahead and do so to see if you can narrow down the range where you should look for a root.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(t):\n",
    "    return -0.74  + 0.765*t + 1.1*t**2 - 3.55*t**3\n",
    "def dg(t):\n",
    "    return 0.765 + 2.2*t - 3*3.55*t**2\n",
    "\n",
    "tset = np.linspace(-1, 1, 100)\n",
    "plt.figure(1, figsize = (6, 5))\n",
    "plt.plot(tset, g(tset), color = 'black')\n",
    "plt.hlines(0, -4, 3, color = 'red', linewidth = 0.75, linestyle = 'dashed') #Adding a y = 0\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-5, 5)\n",
    "plt.xlabel('t', fontsize = 12)\n",
    "plt.ylabel('g', fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving a difficult problem with homebrew Newton-Raphson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t =  5/9\n",
    "# while abs(g(t)) > 1e-6:\n",
    "#     t  = t - g(t)/dg(t)\n",
    "#     print(round(t,10),round(g(t),10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt.newton(g, 5/9, fprime = dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.newton(g, 5/9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A great place for anonymous (lambda functions)\n",
    "\n",
    "Numerical root finding for univariate functions is a great place to get practice with writing and using lambda functions.  For example, let's say I want to solve the function below using an initial guess of x = 10:\n",
    "\n",
    "$$e^x = x^4 + 75.457$$\n",
    "\n",
    "First, I need to make sure I convert this expression into a form 0 = f(x):\n",
    "\n",
    "$$0 = x^4 - e^x + 75.457$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k(x):\n",
    "    return x**4 - np.exp(x) + 75.457 \n",
    "opt.newton(k, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = lambda x: x**4 - np.exp(x) + 75.457\n",
    "opt.newton(k, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.newton(lambda x: x**4 - np.exp(x) + 75.457, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
